{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd # used as operations for manipulating numerical tables and time series.\nidentity = pd.read_csv('../input/ieee-fraud-detection/train_identity.csv')   #reading identity data\ntransaction = pd.read_csv('../input/ieee-fraud-detection/train_transaction.csv')  #reading the transaction data\nimport numpy as np","metadata":{"id":"hZS55QiB9yY6","outputId":"5bb9a2f6-d701-4cc8-af2e-f770db742228","execution":{"iopub.status.busy":"2022-04-28T12:58:39.659884Z","iopub.execute_input":"2022-04-28T12:58:39.660497Z","iopub.status.idle":"2022-04-28T12:59:17.807436Z","shell.execute_reply.started":"2022-04-28T12:58:39.660387Z","shell.execute_reply":"2022-04-28T12:59:17.806697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#function to reduce the memory of dataset\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","metadata":{"id":"Wtize2n1-Xui","execution":{"iopub.status.busy":"2022-04-28T12:59:17.80955Z","iopub.execute_input":"2022-04-28T12:59:17.810566Z","iopub.status.idle":"2022-04-28T12:59:17.826098Z","shell.execute_reply.started":"2022-04-28T12:59:17.810527Z","shell.execute_reply":"2022-04-28T12:59:17.825091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#merging transaction and identity data by using only keys from left dataframe\n#in which primry key acts as TransactionId which is common in both tables, similar to a SQL left outer join.\ntraining = transaction.merge(identity, how = 'left')  ","metadata":{"execution":{"iopub.status.busy":"2022-04-28T12:59:17.83103Z","iopub.execute_input":"2022-04-28T12:59:17.831505Z","iopub.status.idle":"2022-04-28T12:59:27.067637Z","shell.execute_reply.started":"2022-04-28T12:59:17.831471Z","shell.execute_reply":"2022-04-28T12:59:27.066684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training.head()","metadata":{"id":"xq9u4JQVBVun","execution":{"iopub.status.busy":"2022-04-28T12:59:27.068876Z","iopub.execute_input":"2022-04-28T12:59:27.069092Z","iopub.status.idle":"2022-04-28T12:59:27.105392Z","shell.execute_reply.started":"2022-04-28T12:59:27.069065Z","shell.execute_reply":"2022-04-28T12:59:27.104394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"null_columns = [col for col in training.columns if training[col].isnull().sum() / training.shape[0] > 0.9]\ntraining.drop(null_columns,axis=1,inplace=True)\n# col for col iterates over the list training.columns with the variable col and adds it to the resulting list if col is null\n#analyze and drop Rows/Columns with Null values\n#inplace: It is a boolean which makes the changes in data frame itself if True.\n#axis: axis takes int or string value for rows/columns. Input can be 0 or 1 for Integer and ‘index’ or ‘columns’ for String.","metadata":{"id":"l8cy05i_B7Mz","execution":{"iopub.status.busy":"2022-04-28T12:59:27.107176Z","iopub.execute_input":"2022-04-28T12:59:27.107671Z","iopub.status.idle":"2022-04-28T12:59:32.949914Z","shell.execute_reply.started":"2022-04-28T12:59:27.107605Z","shell.execute_reply":"2022-04-28T12:59:32.948917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"filling the missing values with mode values for categorical features and with median for continuous features.\nThe columns with object dtype are the possible categorical features in your dataset.","metadata":{}},{"cell_type":"code","source":"#filling null alues with mean for continuous variables\nfor i in training.columns:\n    if training[i].dtypes=='int64' or training[i].dtypes=='float64':   \n        training[i].fillna(training[i].mean(),inplace=True)","metadata":{"id":"WBo-2f0CCDf5","execution":{"iopub.status.busy":"2022-04-28T12:59:32.951273Z","iopub.execute_input":"2022-04-28T12:59:32.951535Z","iopub.status.idle":"2022-04-28T12:59:35.904825Z","shell.execute_reply.started":"2022-04-28T12:59:32.9515Z","shell.execute_reply":"2022-04-28T12:59:35.903696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#filling null alues with mode for categorical variables\nfor i in training.columns:\n    if training[i].dtypes=='object':     \n        training[i].fillna(training[i].mode()[0],inplace=True)","metadata":{"id":"bMpBwxlsCEia","execution":{"iopub.status.busy":"2022-04-28T12:59:35.906325Z","iopub.execute_input":"2022-04-28T12:59:35.906569Z","iopub.status.idle":"2022-04-28T12:59:38.664638Z","shell.execute_reply.started":"2022-04-28T12:59:35.906539Z","shell.execute_reply":"2022-04-28T12:59:38.663372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#The columns with object dtype are the possible categorical features in your dataset.\ncatagorical_cols = ['id_12','id_15', 'id_16', 'id_23', \n            'id_27', 'id_28', 'id_29','id_30', 'id_31', 'id_33', 'id_34', 'id_35', \n            'id_36', 'id_37', 'id_38', 'DeviceType', 'DeviceInfo', 'ProductCD', 'card4', 'card6', 'M4','P_emaildomain',\n            'R_emaildomain', 'addr1', 'addr2', 'M1', 'M2', 'M3', 'M5', 'M6', 'M7', 'M8', 'M9']","metadata":{"id":"Dmmv4C57Cm7k","execution":{"iopub.status.busy":"2022-04-28T12:59:38.666636Z","iopub.execute_input":"2022-04-28T12:59:38.666896Z","iopub.status.idle":"2022-04-28T12:59:38.674644Z","shell.execute_reply.started":"2022-04-28T12:59:38.666862Z","shell.execute_reply":"2022-04-28T12:59:38.673413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Transformation**","metadata":{}},{"cell_type":"markdown","source":"We are applying label encoding on all the categorical features. For example, ‘Credit_card’ can be assigned as 0, ‘Debit_Card’ can be assigned as 1 and ‘Others’ can be assigned as 2.\n\nThe fit method is calculating the mean and variance of each of the features present in our data. The transform method is transforming all the features using the respective mean and variance.","metadata":{}},{"cell_type":"code","source":"#Label encoder can be used to transform non-numerical labels (as long as they are hashable and comparable) to numerical labels.\n# Basically label encoding is used to convert non-numerical labels such as device type , defice info to numerical labels as 0 , 1 for e.g\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nfor i in catagorical_cols:\n  if i in training.columns:\n    training[i] = le.fit_transform(training[i].astype(str).values) ##Fit label encoder of target values and return encoded labels.","metadata":{"id":"VTtsfRPTCvCP","execution":{"iopub.status.busy":"2022-04-28T12:59:38.678821Z","iopub.execute_input":"2022-04-28T12:59:38.679257Z","iopub.status.idle":"2022-04-28T12:59:51.589355Z","shell.execute_reply.started":"2022-04-28T12:59:38.679206Z","shell.execute_reply":"2022-04-28T12:59:51.588364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y= training['isFraud']\nprint(y.shape)\n","metadata":{"id":"Qn2FPfIPC89-","outputId":"b6bec212-7c91-480d-dd66-7779cac06caa","execution":{"iopub.status.busy":"2022-04-28T12:59:51.590688Z","iopub.execute_input":"2022-04-28T12:59:51.590933Z","iopub.status.idle":"2022-04-28T12:59:51.596515Z","shell.execute_reply.started":"2022-04-28T12:59:51.590903Z","shell.execute_reply":"2022-04-28T12:59:51.595494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = training.drop(['isFraud','TransactionID','TransactionDT'],axis=1)\nprint(x.shape)","metadata":{"id":"9lRdHF4WGkNr","outputId":"0a76327d-9bcb-4853-b020-10d75066e50a","execution":{"iopub.status.busy":"2022-04-28T12:59:51.598308Z","iopub.execute_input":"2022-04-28T12:59:51.599015Z","iopub.status.idle":"2022-04-28T12:59:52.771121Z","shell.execute_reply.started":"2022-04-28T12:59:51.598963Z","shell.execute_reply":"2022-04-28T12:59:52.77008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> The dataset has a highly imbalanced class as we have seen above. There are only 3.5 % fraud cases in our dataset and 96.5% non-fraud cases. We have a ratio of 96.5: 3.5 in our original dataset, we have to divide the dataset for train and test in such a way that both the classes are present in the same proportion in both train and test set. For maintaining the same proportion in the train and test set we have used stratified sampling. We are using 70% of the dataset for training and 30% for testing.\n\n> The features are the descriptive attributes, and the label is what you're attempting to predict or forecast. Here the feature is x and label is y\n\n> here we have to analyze our data whether it is fraud or not whch is available in isFraud so isFraud column will become label of the prediction and rest other columns will be features on which we will be analyzing our model except for transction id and transaction date which is of no relevance here so we will remove both in x.","metadata":{}},{"cell_type":"markdown","source":"The first subset is used to fit the model and is referred to as the training dataset. The second subset is not used to train the model; instead, the input element of the dataset is provided to the model, then predictions are made and compared to the expected values. This second dataset is referred to as the test dataset.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,stratify = y,test_size = 0.3, random_state=1)","metadata":{"id":"LkjtZ1iYDLFo","execution":{"iopub.status.busy":"2022-04-28T12:59:52.772927Z","iopub.execute_input":"2022-04-28T12:59:52.773304Z","iopub.status.idle":"2022-04-28T12:59:57.426068Z","shell.execute_reply.started":"2022-04-28T12:59:52.77327Z","shell.execute_reply":"2022-04-28T12:59:57.424988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"train_test_split Split arrays or matrices into random train and test subsets. (*arrays, test_size=None, train_size=None, random_state=None, shuffle=True, stratify=None) -> list[Any | ndarray | list]\n","metadata":{}},{"cell_type":"code","source":"print(x_train.shape,x_test.shape,y_train.shape,y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T12:59:57.427667Z","iopub.execute_input":"2022-04-28T12:59:57.427978Z","iopub.status.idle":"2022-04-28T12:59:57.434562Z","shell.execute_reply.started":"2022-04-28T12:59:57.427942Z","shell.execute_reply":"2022-04-28T12:59:57.43322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# *Light Gradient Boosting Machine*","metadata":{}},{"cell_type":"markdown","source":"Light Gradient Boosting Machine is a fast distributed, high performance gradient boosting framework based on decision tree algorithm.\n\nWe applied LGBM on our dataset with engineered features and checked for the auc score .The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features. A tree can be seen as a piecewise constant approximation.","metadata":{}},{"cell_type":"markdown","source":"The main difference between Light GBM and other gradient boosting frameworks is that Light GBM expands in a vertical direction means it grows leaf-wise. While the other algorithms expand horizontally in a level-wise direction. Light GBM selects the leaf which produces the least error and maximum efficiency. This method is way more helpful in reducing the error percentage. In short, it grows leaf-wise while others expand level-wise.","metadata":{}},{"cell_type":"markdown","source":"* %timeit will automatically calculate number of runs required for your code based on a total of 2 seconds execution window.\n* lgb.Dataset initilizes dataset\n* params['task'] = 'train' : \n","metadata":{}},{"cell_type":"code","source":"%timeit\nimport lightgbm as lgb\ntrain_lgbm = lgb.Dataset(x_train,label=y_train)\nparams={}\nparams['task'] = 'train'                        #lgbm with different parameters\nparams['boosting_type'] = \"gbdt\"\nparams['application'] = 'classification'\nparams['objective'] = 'binary'\nparams['metric'] = 'auc'\nparams['random_state'] = 1\nmodel = lgb.train(params,train_lgbm, 5000)     #training lgbm model on training set","metadata":{"execution":{"iopub.status.busy":"2022-04-28T12:59:57.436192Z","iopub.execute_input":"2022-04-28T12:59:57.436964Z","iopub.status.idle":"2022-04-28T13:07:14.768073Z","shell.execute_reply.started":"2022-04-28T12:59:57.43691Z","shell.execute_reply":"2022-04-28T13:07:14.7669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict = model.predict(x_test)     #predicting test labels","metadata":{"execution":{"iopub.status.busy":"2022-04-28T13:07:14.771047Z","iopub.execute_input":"2022-04-28T13:07:14.771467Z","iopub.status.idle":"2022-04-28T13:07:43.270431Z","shell.execute_reply.started":"2022-04-28T13:07:14.771404Z","shell.execute_reply":"2022-04-28T13:07:43.269486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict","metadata":{"execution":{"iopub.status.busy":"2022-04-28T13:28:37.401091Z","iopub.execute_input":"2022-04-28T13:28:37.401442Z","iopub.status.idle":"2022-04-28T13:28:37.410432Z","shell.execute_reply.started":"2022-04-28T13:28:37.401408Z","shell.execute_reply":"2022-04-28T13:28:37.409655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict1 = np.array(list(predict))\nfor i in range(len(y_test)):\n  if predict[i]>=0.2:            #setting the threshold at 0.2\n    predict1[i]=1\n  else:\n    predict1[i]=0","metadata":{"execution":{"iopub.status.busy":"2022-04-28T13:27:27.235851Z","iopub.execute_input":"2022-04-28T13:27:27.236442Z","iopub.status.idle":"2022-04-28T13:27:27.419472Z","shell.execute_reply.started":"2022-04-28T13:27:27.236401Z","shell.execute_reply":"2022-04-28T13:27:27.418193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nroc_auc_score(y_test,predict1)    #checking the roc_auc_score\n","metadata":{"execution":{"iopub.status.busy":"2022-04-28T13:27:33.996989Z","iopub.execute_input":"2022-04-28T13:27:33.997377Z","iopub.status.idle":"2022-04-28T13:27:34.048739Z","shell.execute_reply.started":"2022-04-28T13:27:33.99734Z","shell.execute_reply":"2022-04-28T13:27:34.047881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" **Using LGBM and with some feature engineering we have build a model that can predict the class of transaction as fraudulent or non-fraudulent with the confidence of 86%**","metadata":{}},{"cell_type":"markdown","source":"# Conclusion :\n","metadata":{}},{"cell_type":"markdown","source":"> ## **After all the analysis and applying different machine learning algorithms we can say that by using LGBM with all the engineered features we can predict the Class of the transactions as fraudulent or non-fraudulent with 86% of confidence level.**","metadata":{}}]}