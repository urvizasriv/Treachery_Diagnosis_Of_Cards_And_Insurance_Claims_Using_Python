{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd # used as operations for manipulating numerical tables and time series.\nidentity = pd.read_csv('../input/ieee-fraud-detection/train_identity.csv')   #reading identity data\ntransaction = pd.read_csv('../input/ieee-fraud-detection/train_transaction.csv')  #reading the transaction data\nimport numpy as np","metadata":{"id":"hZS55QiB9yY6","outputId":"5bb9a2f6-d701-4cc8-af2e-f770db742228","execution":{"iopub.status.busy":"2022-04-28T15:26:24.591584Z","iopub.execute_input":"2022-04-28T15:26:24.591999Z","iopub.status.idle":"2022-04-28T15:26:53.287394Z","shell.execute_reply.started":"2022-04-28T15:26:24.591913Z","shell.execute_reply":"2022-04-28T15:26:53.286770Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#function to reduce the memory of dataset\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","metadata":{"id":"Wtize2n1-Xui","execution":{"iopub.status.busy":"2022-04-28T15:26:53.288614Z","iopub.execute_input":"2022-04-28T15:26:53.289228Z","iopub.status.idle":"2022-04-28T15:26:53.300821Z","shell.execute_reply.started":"2022-04-28T15:26:53.289196Z","shell.execute_reply":"2022-04-28T15:26:53.299765Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#merging transaction and identity data by using only keys from left dataframe\n#in which primry key acts as TransactionId which is common in both tables, similar to a SQL left outer join.\ntraining = transaction.merge(identity, how = 'left')  ","metadata":{"execution":{"iopub.status.busy":"2022-04-28T15:26:53.301929Z","iopub.execute_input":"2022-04-28T15:26:53.302126Z","iopub.status.idle":"2022-04-28T15:27:00.480626Z","shell.execute_reply.started":"2022-04-28T15:26:53.302103Z","shell.execute_reply":"2022-04-28T15:27:00.479753Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"training.head()","metadata":{"id":"xq9u4JQVBVun","execution":{"iopub.status.busy":"2022-04-28T15:27:00.482151Z","iopub.execute_input":"2022-04-28T15:27:00.482392Z","iopub.status.idle":"2022-04-28T15:27:00.513780Z","shell.execute_reply.started":"2022-04-28T15:27:00.482361Z","shell.execute_reply":"2022-04-28T15:27:00.512921Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"null_columns = [col for col in training.columns if training[col].isnull().sum() / training.shape[0] > 0.9]\ntraining.drop(null_columns,axis=1,inplace=True)\n# col for col iterates over the list training.columns with the variable col and adds it to the resulting list if col is null\n#analyze and drop Rows/Columns with Null values\n#inplace: It is a boolean which makes the changes in data frame itself if True.\n#axis: axis takes int or string value for rows/columns. Input can be 0 or 1 for Integer and ‘index’ or ‘columns’ for String.","metadata":{"id":"l8cy05i_B7Mz","execution":{"iopub.status.busy":"2022-04-28T15:27:00.515937Z","iopub.execute_input":"2022-04-28T15:27:00.516157Z","iopub.status.idle":"2022-04-28T15:27:04.536423Z","shell.execute_reply.started":"2022-04-28T15:27:00.516132Z","shell.execute_reply":"2022-04-28T15:27:04.535657Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"filling the missing values with mode values for categorical features and with median for continuous features.\nThe columns with object dtype are the possible categorical features in your dataset.","metadata":{}},{"cell_type":"code","source":"#filling null alues with mean for continuous variables\nfor i in training.columns:\n    if training[i].dtypes=='int64' or training[i].dtypes=='float64':   \n        training[i].fillna(training[i].mean(),inplace=True)","metadata":{"id":"WBo-2f0CCDf5","execution":{"iopub.status.busy":"2022-04-28T15:27:04.537718Z","iopub.execute_input":"2022-04-28T15:27:04.538016Z","iopub.status.idle":"2022-04-28T15:27:06.949068Z","shell.execute_reply.started":"2022-04-28T15:27:04.537977Z","shell.execute_reply":"2022-04-28T15:27:06.948277Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#filling null alues with mode for categorical variables\nfor i in training.columns:\n    if training[i].dtypes=='object':     \n        training[i].fillna(training[i].mode()[0],inplace=True)","metadata":{"id":"bMpBwxlsCEia","execution":{"iopub.status.busy":"2022-04-28T15:27:06.950274Z","iopub.execute_input":"2022-04-28T15:27:06.950591Z","iopub.status.idle":"2022-04-28T15:27:08.415479Z","shell.execute_reply.started":"2022-04-28T15:27:06.950552Z","shell.execute_reply":"2022-04-28T15:27:08.414783Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#The columns with object dtype are the possible categorical features in your dataset.\ncatagorical_cols = ['id_12','id_15', 'id_16', 'id_23', \n            'id_27', 'id_28', 'id_29','id_30', 'id_31', 'id_33', 'id_34', 'id_35', \n            'id_36', 'id_37', 'id_38', 'DeviceType', 'DeviceInfo', 'ProductCD', 'card4', 'card6', 'M4','P_emaildomain',\n            'R_emaildomain', 'addr1', 'addr2', 'M1', 'M2', 'M3', 'M5', 'M6', 'M7', 'M8', 'M9']","metadata":{"id":"Dmmv4C57Cm7k","execution":{"iopub.status.busy":"2022-04-28T15:27:08.416525Z","iopub.execute_input":"2022-04-28T15:27:08.417211Z","iopub.status.idle":"2022-04-28T15:27:08.422120Z","shell.execute_reply.started":"2022-04-28T15:27:08.417178Z","shell.execute_reply":"2022-04-28T15:27:08.421236Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# **Data Transformation**","metadata":{}},{"cell_type":"markdown","source":"We are applying label encoding on all the categorical features. For example, ‘Credit_card’ can be assigned as 0, ‘Debit_Card’ can be assigned as 1 and ‘Others’ can be assigned as 2.\n\nThe fit method is calculating the mean and variance of each of the features present in our data. The transform method is transforming all the features using the respective mean and variance.","metadata":{}},{"cell_type":"code","source":"#Label encoder can be used to transform non-numerical labels (as long as they are hashable and comparable) to numerical labels.\n# Basically label encoding is used to convert non-numerical labels such as device type , defice info to numerical labels as 0 , 1 for e.g\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nfor i in catagorical_cols:\n  if i in training.columns:\n    training[i] = le.fit_transform(training[i].astype(str).values) ##Fit label encoder of target values and return encoded labels.","metadata":{"id":"VTtsfRPTCvCP","execution":{"iopub.status.busy":"2022-04-28T15:27:08.423579Z","iopub.execute_input":"2022-04-28T15:27:08.423850Z","iopub.status.idle":"2022-04-28T15:27:17.190763Z","shell.execute_reply.started":"2022-04-28T15:27:08.423822Z","shell.execute_reply":"2022-04-28T15:27:17.189873Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"y= training['isFraud']\nprint(y.shape)\n","metadata":{"id":"Qn2FPfIPC89-","outputId":"b6bec212-7c91-480d-dd66-7779cac06caa","execution":{"iopub.status.busy":"2022-04-28T15:27:17.192353Z","iopub.execute_input":"2022-04-28T15:27:17.192907Z","iopub.status.idle":"2022-04-28T15:27:17.198236Z","shell.execute_reply.started":"2022-04-28T15:27:17.192866Z","shell.execute_reply":"2022-04-28T15:27:17.197360Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"x = training.drop(['isFraud','TransactionID','TransactionDT'],axis=1)\nprint(x.shape)","metadata":{"id":"9lRdHF4WGkNr","outputId":"0a76327d-9bcb-4853-b020-10d75066e50a","execution":{"iopub.status.busy":"2022-04-28T15:27:17.199603Z","iopub.execute_input":"2022-04-28T15:27:17.199836Z","iopub.status.idle":"2022-04-28T15:27:17.897493Z","shell.execute_reply.started":"2022-04-28T15:27:17.199808Z","shell.execute_reply":"2022-04-28T15:27:17.896540Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"> The dataset has a highly imbalanced class as we have seen above. There are only 3.5 % fraud cases in our dataset and 96.5% non-fraud cases. We have a ratio of 96.5: 3.5 in our original dataset, we have to divide the dataset for train and test in such a way that both the classes are present in the same proportion in both train and test set. For maintaining the same proportion in the train and test set we have used stratified sampling. We are using 70% of the dataset for training and 30% for testing.\n\n> The features are the descriptive attributes, and the label is what you're attempting to predict or forecast. Here the feature is x and label is y\n\n> here we have to analyze our data whether it is fraud or not whch is available in isFraud so isFraud column will become label of the prediction and rest other columns will be features on which we will be analyzing our model except for transction id and transaction date which is of no relevance here so we will remove both in x.","metadata":{}},{"cell_type":"markdown","source":"The first subset is used to fit the model and is referred to as the training dataset. The second subset is not used to train the model; instead, the input element of the dataset is provided to the model, then predictions are made and compared to the expected values. This second dataset is referred to as the test dataset.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,stratify = y,test_size = 0.3, random_state=1)","metadata":{"id":"LkjtZ1iYDLFo","execution":{"iopub.status.busy":"2022-04-28T15:27:17.898975Z","iopub.execute_input":"2022-04-28T15:27:17.899180Z","iopub.status.idle":"2022-04-28T15:27:20.821317Z","shell.execute_reply.started":"2022-04-28T15:27:17.899156Z","shell.execute_reply":"2022-04-28T15:27:20.820404Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"train_test_split Split arrays or matrices into random train and test subsets. (*arrays, test_size=None, train_size=None, random_state=None, shuffle=True, stratify=None) -> list[Any | ndarray | list]\n","metadata":{}},{"cell_type":"code","source":"print(x_train.shape,x_test.shape,y_train.shape,y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T15:27:20.822475Z","iopub.execute_input":"2022-04-28T15:27:20.822715Z","iopub.status.idle":"2022-04-28T15:27:20.828936Z","shell.execute_reply.started":"2022-04-28T15:27:20.822687Z","shell.execute_reply":"2022-04-28T15:27:20.827854Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# **Decision Tree**","metadata":{}},{"cell_type":"markdown","source":"The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features. A tree can be seen as a piecewise constant approximation.","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nmodel = DecisionTreeClassifier(random_state=1) #Random_state is used to set the seed for the random generator so that we can ensure that the results that we get can be reproduced\nmodel.fit(x_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T15:27:20.831924Z","iopub.execute_input":"2022-04-28T15:27:20.832193Z","iopub.status.idle":"2022-04-28T15:29:27.610026Z","shell.execute_reply.started":"2022-04-28T15:27:20.832150Z","shell.execute_reply":"2022-04-28T15:29:27.609111Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"predict = model.predict(x_test) #Predict class or regression value for X.","metadata":{"execution":{"iopub.status.busy":"2022-04-28T15:29:27.611144Z","iopub.execute_input":"2022-04-28T15:29:27.611672Z","iopub.status.idle":"2022-04-28T15:29:28.129015Z","shell.execute_reply.started":"2022-04-28T15:29:27.611638Z","shell.execute_reply":"2022-04-28T15:29:28.128148Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nroc_auc_score(y_test,predict)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T15:29:28.130293Z","iopub.execute_input":"2022-04-28T15:29:28.130793Z","iopub.status.idle":"2022-04-28T15:29:28.170698Z","shell.execute_reply.started":"2022-04-28T15:29:28.130760Z","shell.execute_reply":"2022-04-28T15:29:28.169716Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## We applied a decision tree classifier on our model and got auc_score of 0.78 which is much better then we got in logistic regression. Decision tree performed much better than logistic regression.","metadata":{}}]}